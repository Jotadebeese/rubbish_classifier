{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rubbish Classifier\n",
    "\n",
    "This is the first attend to create a rubbish classifier by creating a Deep Learning model using computer vision."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing PyTorch and setting up device-agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "\n",
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting data\n",
    "\n",
    "For our rubbish clasifier we have the following nine label classes:\n",
    "\n",
    "1. cans (softdrinks, beer, etc..)\n",
    "2. carton_boxes (Milk boxes, Juice Boxes, etc...)\n",
    "3. coffee_cups (Takeaway coffe cups)\n",
    "4. glass_bottles (Beer bottles, wine bottles, spirits bottles, etc...)\n",
    "5. paper_bags (Shopping paper bags)\n",
    "6. plastic_bags (shopping plastic bags)\n",
    "7. plastic_bottles (Milk plastic bottles, water, juices, etc...)\n",
    "8. takeaway_containers (carboard takeaway conteiners)\n",
    "9. tissues (tissues, napkins)\n",
    "\n",
    "Where the ideal is to divide the data into 75% train data and 25% test data.\n",
    "\n",
    "However, `rubbish_classifier_v0.001` is our first approach, so at the moment we have enough data to train only on the classes **cans, carton_boxes, coffee_cups** and **glass_bottles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data\\images_dataset' does not exist, creating directory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1M-jVb1fw5TZrHsBecIE-EYDkcNVqoCSq\n",
      "To: c:\\Users\\juanb\\Documents\\AI\\rubbish_classifier\\data\\images.zip\n",
      "100%|██████████| 481M/481M [00:25<00:00, 19.1MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping data...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup a path to a data folder\n",
    "data_path = Path(\"data/\")\n",
    "images_path = data_path / \"images_dataset\"\n",
    "\n",
    "# If the data folder doesn't exist, download it and prepare it.\n",
    "if images_path.is_dir():\n",
    "    print(f\"'{images_path}' directory already exists, skipping directory creation...\")\n",
    "else:\n",
    "    print(f\"'{images_path}' does not exist, creating directory...\")\n",
    "    images_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download data\n",
    "try:\n",
    "    import gdown\n",
    "except:\n",
    "    !pip install gdown\n",
    "    import gdown\n",
    "\n",
    "url = 'https://drive.google.com/uc?id=1M-jVb1fw5TZrHsBecIE-EYDkcNVqoCSq'\n",
    "output = str(data_path)+'/images.zip'\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "# Unzip data\n",
    "with zipfile.ZipFile(data_path / \"images.zip\", \"r\") as zip_ref:\n",
    "    print(\"Unzipping data...\")\n",
    "    zip_ref.extractall(data_path)\n",
    "    \n",
    "os.remove(str(data_path)+\"/images.zip\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Converting all images to jpg format\n",
    "\n",
    "`tqdm` source https://github.com/tqdm/tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucntion to convert from any image format to jpg\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# Install tqdm to show smart progess meter\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except:\n",
    "    !pip install tqdm\n",
    "    from tqdm import tqdm\n",
    "\n",
    "def image_convertor(path: str, format: str):\n",
    "    count=0\n",
    "    path=Path(path)\n",
    "    for file in tqdm(path.glob(\"./*\")):\n",
    "        f, e = os.path.splitext(file)\n",
    "        renameFile = f + \".\"+format.lower()\n",
    "        if e.lower() != \".\"+format.lower():\n",
    "            old_file=file\n",
    "            count+=1\n",
    "            try:\n",
    "                with Image.open(file) as img:\n",
    "                    img.save(renameFile)\n",
    "            except OSError:\n",
    "                print(\"cannot convert\", file)\n",
    "            os.remove(old_file)\n",
    "    print(f\"{count} images converted to '{format}' in '{path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112it [00:00, 55494.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images converted to 'jpg' in 'data\\dataset\\cans'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89it [00:07, 11.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 images converted to 'jpg' in 'data\\dataset\\carton_boxes'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169it [00:14, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 images converted to 'jpg' in 'data\\dataset\\coffee_cups'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [00:04, 25.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 images converted to 'jpg' in 'data\\dataset\\glass_bottles'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# cans class convertion\n",
    "image_convertor(path=\"data/dataset/cans/\",\n",
    "                format=\"jpg\")\n",
    "# carton_boxes class convertion\n",
    "image_convertor(path=\"data/dataset/carton_boxes/\",\n",
    "                format=\"jpg\")\n",
    "# coffee_cups class convertion\n",
    "image_convertor(path=\"data/dataset/coffee_cups/\",\n",
    "                format=\"jpg\")\n",
    "# glass_bottles class convertion\n",
    "image_convertor(path=\"data/dataset/glass_bottles/\",\n",
    "                format=\"jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Split data into train and test dataset by using `split-folders`\n",
    "\n",
    "Source https://github.com/jfilter/split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 491 files [00:00, 1111.91 files/s]\n"
     ]
    }
   ],
   "source": [
    "# get split-folders ready to use\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "    import splitfolders\n",
    "except:\n",
    "    !pip install split-folders[full]\n",
    "    import splitfolders\n",
    "\n",
    "# Define input and output folders\n",
    "input_folder = \"data/dataset/\"\n",
    "output_folder = str(images_path)\n",
    "\n",
    "splitfolders.fixed(input_folder, output= output_folder,\n",
    "                   seed=42, fixed=(0, 30), move=True)\n",
    "\n",
    "shutil.rmtree(\"data/dataset\")\n",
    "shutil.rmtree(\"data\\images_dataset/val\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b14cf466242c0b02430e6946b27dbc382f4a26433a23de128b80968fcca4f013"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
